



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta http-equiv="x-dns-prefetch-control" content="on">
      <link rel="dns-prefetch" href="//oi-wiki.org">
      <link rel="dns-prefetch" href="//search.oi-wiki.org">
      <link rel="dns-prefetch" href="//api.github.com">
      <link rel="dns-prefetch" href="//www.google-analytics.com">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Record mathematics, Program and Engineer">
      
      
        <link rel="canonical" href="https://www.wweiying.top/start/ai/">
      
      
        <meta name="author" content="W">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../favicon/favicon-32x32.png">
      <meta name="generator" content="mkdocs-1.2.4, mkdocs-material-4.4.2">
    
    
      
        <title>人工智能 - Record mathematics, Program and Engineer</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.6f7cfa25.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
      <script src="../../assets/javascripts/modernizr.27508f0e.js"></script>
    
    
      
        <style>@font-face{font-family:'Fira Sans';font-style:normal;font-weight:300;src:url(//lib.baomitu.com/fonts/fira-sans/fira-sans-300.eot);src:local('Fira Sans'),local('FiraSans-Normal'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-300.eot?#iefix) format('embedded-opentype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-300.woff2) format('woff2'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-300.woff) format('woff'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-300.ttf) format('truetype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-300.svg#FiraSans) format('svg')}@font-face{font-family:'Fira Sans';font-style:normal;font-weight:regular;src:url(//lib.baomitu.com/fonts/fira-sans/fira-sans-regular.eot);src:local('Fira Sans'),local('FiraSans-Normal'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-regular.eot?#iefix) format('embedded-opentype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-regular.woff2) format('woff2'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-regular.woff) format('woff'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-regular.ttf) format('truetype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-regular.svg#FiraSans) format('svg')}@font-face{font-family:'Fira Sans';font-style:italic;font-weight:regular;src:url(//lib.baomitu.com/fonts/fira-sans/fira-sans-italic.eot);src:local('Fira Sans'),local('FiraSans-Italic'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-italic.eot?#iefix) format('embedded-opentype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-italic.woff2) format('woff2'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-italic.woff) format('woff'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-italic.ttf) format('truetype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-italic.svg#FiraSans) format('svg')}@font-face{font-family:'Fira Sans';font-style:normal;font-weight:700;src:url(//lib.baomitu.com/fonts/fira-sans/fira-sans-700.eot);src:local('Fira Sans'),local('FiraSans-Normal'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-700.eot?#iefix) format('embedded-opentype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-700.woff2) format('woff2'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-700.woff) format('woff'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-700.ttf) format('truetype'),url(//lib.baomitu.com/fonts/fira-sans/fira-sans-700.svg#FiraSans) format('svg')}@font-face{font-family:'Fira Mono';font-style:normal;font-weight:regular;src:url(//lib.baomitu.com/fonts/fira-mono/fira-mono-regular.eot);src:local('Fira Mono'),local('FiraMono-Normal'),url(//lib.baomitu.com/fonts/fira-mono/fira-mono-regular.eot?#iefix) format('embedded-opentype'),url(//lib.baomitu.com/fonts/fira-mono/fira-mono-regular.woff2) format('woff2'),url(//lib.baomitu.com/fonts/fira-mono/fira-mono-regular.woff) format('woff'),url(//lib.baomitu.com/fonts/fira-mono/fira-mono-regular.ttf) format('truetype'),url(//lib.baomitu.com/fonts/fira-mono/fira-mono-regular.svg#FiraMono) format('svg')}body,input{font-family:"Fira Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Fira Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/vendor/material-icons/iconfont/material-icons.css">
    
      <link rel="manifest" href="../../manifest.webmanifest">
    
    
      <link rel="stylesheet" href="../../_static/css/extra.css?v=13">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "G-BQRVKTPNPP", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="white" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://www.wweiying.top/" title="Record mathematics, Program and Engineer" class="md-header-nav__button md-logo">
          
            <img src="../../favicon/favicon-256x256.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Record mathematics, Program and Engineer
            </span>
            <span class="md-header-nav__topic">
              
                人工智能
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/WWeiying/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Weiying's github
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../.." class="md-tabs__link md-tabs__link--active">
          开始
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../website/" class="md-tabs__link">
          网站和工具
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../experience/wrongs/" class="md-tabs__link">
          经验
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://www.wweiying.top/" title="Record mathematics, Program and Engineer" class="md-nav__button md-logo">
      
        <img src="../../favicon/favicon-256x256.png" width="48" height="48">
      
    </a>
    Record mathematics, Program and Engineer
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/WWeiying/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Weiying's github
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1" checked>
    
    <label class="md-nav__link" for="nav-1">
      开始
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        开始
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../.." title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../format/" title="格式" class="md-nav__link">
      格式
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        人工智能
      </label>
    
    <a href="./" title="人工智能" class="md-nav__link md-nav__link--active">
      人工智能
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    论文笔记
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    Alexnet——深度学习浪潮奠基作之一
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    Resnet
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      网站和工具
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        网站和工具
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../website/" title="网站和工具" class="md-nav__link">
      网站和工具
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      经验
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        经验
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../experience/wrongs/" title="走过的坑" class="md-nav__link">
      走过的坑
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    论文笔记
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    Alexnet——深度学习浪潮奠基作之一
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    Resnet
  </a>
  
</li>
      
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/WWeiying/edit/master/docs/start/ai.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                  <h1>人工智能</h1>
                
                <table>
<thead>
<tr>
<th align="center">的萨芬</th>
<th align="center">大师傅</th>
<th>十分大</th>
<th>的萨芬</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="F:\学习\论文\Alexnet.pdf">Alexnet</a></td>
<td align="center">2012</td>
<td></td>
<td></td>
</tr>
<tr>
<td align="center"><a href="F:\学习\论文\Resnet.pdf/">Resnet</a></td>
<td align="center">2015</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="_1">论文笔记<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<h3 id="alexnet">Alexnet——深度学习浪潮奠基作之一<a class="headerlink" href="#alexnet" title="Permanent link">&para;</a></h3>
<blockquote>
<p>ImageNet Classification with Deep Convolutional Neural Networks</p>
</blockquote>
<p>Geoffrey E. Hinton          Jeff Dean</p>
<p>银河系漫游指南：42是宇宙的答案</p>
<p>dirty trick：图片增强、Relu、dropout</p>
<p>NeuralPS 是机器学习最好的会议</p>
<h4 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h4>
<p>我们训练了一个很大的、很深的卷积神经网络对1000类120万张高分辨率的图片进行分类。在测试集上，我们实现top-1的错误率是37.5%，top-5的错误率是17.0%，比前面的工作都要好。这个神经网络有6千万个参数和65万个神经元，有5个卷积层组成，后面跟着最大池化层和有1000路softmax的三个全连接层。为了更快地训练，我们用非饱和神经元和一个GPU实现的卷积运算。为了在全连接层减少过拟合，我们使用最近开发的叫“dropout”的正则化方法，这证明是非常有效的。为了减少过拟合，我们用了正则的方法叫“dropout”。我们还做了这个模型的一个变体，并且top-5的15.3%错误率胜过第二名的26.2%。</p>
<blockquote>
<p>做了一个……的模型；模型的结果特别好；这个模型是什么样的。为了更快地训练，做了……；为了减少过拟合，做了……；我们比第二名的好很多。</p>
</blockquote>
<h4 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h4>
<p>当前目标识别的方法主要使用机器学习的方法。为了提高性能，我们收集更大的数据集，训练更强大的模型，使用更好的技术来避免过拟合。直到最近，有标签图像的数据集还是相对较小的，大约有几万张图像（NORB，Caltech，CIFAR）。在这个规模大小的数据集下，简单的识别任务能够被很好的解决，尤其这些数据还保留了标签。例如，MNIST数字识别任务的当前最好的错误率（0.3％）接近人类表现。但现实环境中的物体表现出相当大的可变性，所以要学会识别它们，有必要使用更大的训练集。事实上，小图像数据集的缺点已经被广泛认识到，但直到最近才有可能收集有数百万张图像的有标签数据集。新的更大的数据集包括LabelMe和ImageNet。LabelMe由数十万张完全分割的图像组成，ImageNet[6]由超过1500万张有标签的高分辨率图像组成，分类超过22000个。</p>
<blockquote>
<p>我们追求更大规模的数据集避免过拟合、提高性能；过去有标签的数据集规模很小，这是有很大缺陷的，简单的任务还凑活，真实的复杂环境就不太行了；现在大规模的带标签数据集出现了，ImageNet、LabelMe。</p>
</blockquote>
<p>为了从数百万张图像中了解成千上万个物体，我们需要一个学习能力很强的模型。然而，目标识别任务的巨大复杂性意味着即使使用了Imagenet这样大规模的数据集，这个问题也无法详细阐明，因此我们的模型应该有许多先验知识去弥补所有我们没有的数据。卷积神经网络就是这样一类模型。可以通过变化它们的宽度和深度去控制他们的能力，并且它们还可以对图像的性质(即统计的平稳性和像素依赖的局部性)做出强大的并且大部分是正确的假设。因此，和每层相近大小的标准前馈神经网络相比，卷积神经网络有少得多的连接和参数，因此卷积神经网络训练更简单，然而它们的理论最好性能仅仅比标准前馈神经网络差一点。</p>
<blockquote>
<p>目标识别任务十分复杂，需要学习能力很强的模型。即使用了很大规模的数据集也无法阐明任务的复杂性，模型需要先验知识去弥补没有的数据。卷积神经网络就是这样的，有很多优点，简单而又高效。</p>
</blockquote>
<p>卷积神经网络具有很多吸引人的性质，它们的局部结构效率相当高，但是要应用在大规模的高分辨率图像中依然十分昂贵。幸运的是，当前的GPU与高度优化的2D卷积的实现相结合，已经足够强大，可以加快大规模卷积神经网络的训练，而且最近的数据集(如ImageNet)包含足够多的带标签的样本，可以去训练没有严重过拟合的大规模卷积神经网络。</p>
<p>这篇论文的明确贡献如下所示：我们在ImageNet数据集的子集上训练了一个最大的卷积神经网络，并且在这些数据集上实现了目前为止报告的最好结果。我们写了高度优化的2D卷积的GPU实现和训练卷积神经网络固有的其他操作，我们公开实现方法。我们的网络包含了一些新的和不寻常的特征，这些特征可以提高它的性能并减少它的训练时间，这些特征将在第3节详细介绍。我们网络的规模使过拟合成为一个重要的问题，即使有120万个有标签的训练样本，所以我们使用了几个有效技术来防止过拟合，这在第4节中描述。我们最终的网络包含5个卷积层和3个完全连接层，这个深度似乎很重要：我们发现，移除任何卷积层(每个卷积层包含的模型参数不超过1%)都会导致性能变差。</p>
<blockquote>
<p>论文贡献：</p>
<ul>
<li>训练了一个最大的CNN，实现了最好结果；</li>
<li>用GPU实现了CNN的2D卷积和其他操作；</li>
<li>网络有新的特征，提高了性能，减少了训练时间；</li>
<li>网络采取了防止过拟合的技术；</li>
<li>最终的网络形态，深度很重要。</li>
</ul>
</blockquote>
<p>最后，网络的大小主要限制于当前GPU上可用的内存和我们愿意容忍的训练时间。在两块GTX 580 3GB gpu上，我们花费了5到6天的时间去训练网络。我们所有的实验都表明，只要有更快的GPU和更大的数据集，我们的结果就可以得到改善。</p>
<blockquote>
<p>过拟合代表了深度学习的一个派别，深度学习在未来几年使用很大很大的模型，用正则避免过拟合，这是当时的认知。</p>
<p>end to end：原始图片、文本直接进去，不做任何特征提取，神经网络能做出来。</p>
</blockquote>
<h4 id="2-the-dataset">2. The Dataset<a class="headerlink" href="#2-the-dataset" title="Permanent link">&para;</a></h4>
<p>ImageNet是一个包含超过1500万张标签高分辨率图像的数据集，它们大约属于22000个类别。这些图像是从网络上收集来的，然后进行人工标记。从2010年开始，作为帕斯卡视觉对象挑战赛的一部分，一个被称为ILSVRC的年度竞赛被举办。总共大约有120万张训练图像，5万张验证图像，15万测试图像。</p>
<p>ILSVRC-2010是ILSVRC竞赛能够得到测试集标签的唯一版本，因此这是我们进行绝大多数实验的版本。因为我们也在ILSVRC-2012竞赛中加入了我们的模型，在第6节中，我们也报告了我们在这个版本数据集上的结果，对于这个版本的数据集，测试集标签是不可用的。在ImageNet上，通常报告两种错误率：top-1和top-5，其中top-5错误率是指正确标签不在模型认为最可能的五个标签之列的测试图像的比例。</p>
<blockquote>
<p>top-5 error rate: 给出五个最可能的结果，正确结果不在五个中间的概率。top-1 error rate: 给一个结果的错误概率。</p>
</blockquote>
<p>ImageNet由不同分辨率的图像组成，而我们的系统需要恒定的输入维度。因此，我们将图像下采样到<span class="arithmatex"><span class="MathJax_Preview">256\times256</span><script type="math/tex">256\times256</script></span>的固定分辨率。给定一个矩形图像，我们首先缩放图像，使短边的长度为256，然后从结果图像中裁剪出中间的<span class="arithmatex"><span class="MathJax_Preview">256\times256</span><script type="math/tex">256\times256</script></span>部分。我们没有以任何其他方式预处理图像，除了在训练集上在像素级别上的剪裁。因此，我们根据像素的(居中)原始RGB值来训练我们的网络。</p>
<h4 id="3-the-architecture">3. The Architecture<a class="headerlink" href="#3-the-architecture" title="Permanent link">&para;</a></h4>
<p>图2总结了我们网络的架构。它包含8个学习层——5个卷积层和3个全连接层。下面，我们将描述网络架构的一些新颖或不寻常的特征。3.1-3.4节是根据我们对其重要性的估计进行排序的，最重要的放在第一位。</p>
<h5 id="31-relu-nonlinearity">3.1 ReLU Nonlinearity<a class="headerlink" href="#31-relu-nonlinearity" title="Permanent link">&para;</a></h5>
<p>对一个神经元的输出<span class="arithmatex"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>和它的输入<span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>之间函数关系建模的标准方法是<span class="arithmatex"><span class="MathJax_Preview">f(x)=tanh(x)</span><script type="math/tex">f(x)=tanh(x)</script></span>或<span class="arithmatex"><span class="MathJax_Preview">f(x)=(1+e^{-x})^{-1}</span><script type="math/tex">f(x)=(1+e^{-x})^{-1}</script></span>。关于梯度下降的训练时间，这些<strong>饱和</strong>的非线性激活函数比<strong>非饱和</strong>的非线性激活函数<span class="arithmatex"><span class="MathJax_Preview">f(x)=max(0,x)</span><script type="math/tex">f(x)=max(0,x)</script></span>​要慢得多（relu比tanh要快，relu比较简单）。沿袭Nair和Hinton的说法，我们将具有这种非线性神经单元称为“校正线性单元”（ReLUs）。使用ReLUs的深度卷积神经网络的训练速度比使用tanh单元的同类网络快好几倍。这在图1得到证明，图1显示了特定的四层卷积网络在CIFAR-10数据集上达到25%训练误差所需的迭代次数。这张图表明，如果我们使用传统的饱和神经元模型，我们就无法用这么大的神经网络来进行这项工作。</p>
<p>我们不是第一个考虑在CNN中替代传统神经元模型的。例如，Jarrett声称非线性函数<span class="arithmatex"><span class="MathJax_Preview">f(x)=\mid tanh(x)\mid</span><script type="math/tex">f(x)=\mid tanh(x)\mid</script></span>和对比归一化、局部平均池化在Caltech-101数据集上工作的非常好。然而，在这个数据集上主要关注的是防止过拟合，因此他们观察到的效果与我们使用ReLU时报告的拟合训练集的加速能力不同。更快地学习对于在大规模数据集上训练的大模型的性能有很大的影响。</p>
<h5 id="32-training-on-multiple-gpus">3.2 Training on Multiple GPUs<a class="headerlink" href="#32-training-on-multiple-gpus" title="Permanent link">&para;</a></h5>
<p>单个GTX 580 GPU只有3GB内存，这限制了可以在GPU上训练的网络的最大尺寸。事实证明，120万个训练示例足以训练一个GPU无法容纳的庞大网络。因此，我们将网络分配到两个GPU上。现在的GPU特别适合跨GPU并行化，因为它们能够直接读写彼此的内存，而不需要经过主机内存。我们使用的并行化方案基本上是把一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧：GPU只在特定的层进行通信。这意味着，例如，第3层的内核从第2层的所有内核映射中获取输入。然而，第4层的内核只从位于同一GPU上的第3层的那些内核映射中获取输入。选择连接模式是交叉验证的一个问题，但这允许我们精确地调整通信量，直到达到可以接受的计算量。</p>
<p>最终的结构与Ciressan所采用的“柱状”CNN有些相似，但我们的column不是独立的(见图2)。一个GPU上训练的每个卷积层上有很多神经元与一个网络有一半神经元相比较，这个方案将我们的top-1和top-5错误率分别降低了1.7%和1.2%。双GPU网络的训练时间比单GPU网络略短。</p>
<blockquote>
<p>在最终的卷积层中，单gpu网络事实上拥有与双gpu网络相同数量的核。这是因为网络的大部分参数都在第一层全连接层，它以最后一层卷积层作为输入。因此，为了使两个网络具有大致相同的参数数量，我们没有将最终的卷积层(也没有将随后的完全连接层)的大小减半。因此，这种比较偏向于单gpu网络，因为它比双gpu网络的“一半大小”要大。</p>
</blockquote>
<h5 id="33-local-response-normaliztion">3.3 Local Response Normaliztion<a class="headerlink" href="#33-local-response-normaliztion" title="Permanent link">&para;</a></h5>
<p>ReLU具有不需要输入正则化来防止饱和的理想特性。如果至少有一些训练样本对ReLU产生正的输入，学习就会在那个神经元中发生。然而，我们仍然发现下面的局部正则化方案有助于泛化。核<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>在位置<span class="arithmatex"><span class="MathJax_Preview">(x,y)</span><script type="math/tex">(x,y)</script></span>处计算出的神经元的活动用<span class="arithmatex"><span class="MathJax_Preview">a_{x,y}^i</span><script type="math/tex">a_{x,y}^i</script></span>来表示，然后使用ReLU非线性激活函数，正则化的响应活动<span class="arithmatex"><span class="MathJax_Preview">b_{x,y}^i</span><script type="math/tex">b_{x,y}^i</script></span>用下式表示：
$$
b_{x,y}<sup>i=a_{x,y}</sup>i/(k+\alpha \sum_{j=\max (0,i-n/2)}^{\min (N-1,i+n/2)}(a_{x,y}<sup>j)</sup>2)^\beta
$$
在上式中，<span class="arithmatex"><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span>是映射到相同空间位置的核的总数，<span class="arithmatex"><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span>是这层核的总数。核映射的顺序当然是任意的，并且在训练开始之前就确定了。这种响应正则化实现了一种侧向抑制的形式，这种形式受到真实神经元中发现的那种类型的启发，在使用不同核计算得到的神经元输出之间产生了大规模活动的竞争。常量<span class="arithmatex"><span class="MathJax_Preview">k,n,\alpha,\beta</span><script type="math/tex">k,n,\alpha,\beta</script></span>是超参数，它们的值用验证集来确定；我们用<span class="arithmatex"><span class="MathJax_Preview">k=2,n=5,\alpha=10^{-4},\beta=0.75</span><script type="math/tex">k=2,n=5,\alpha=10^{-4},\beta=0.75</script></span>。在某些层应用了ReLU非线性激活函数后，我们使用了这种正则化。</p>
<p>该方案与Jarrett等人的局部对比正则化方案有一些相似之处，但是我们的“brightness normalization”更合适，因为我们没有减去平均活动。响应正则化分别降低了我们的top-1，top-5错误率1.4%，1.2%个百分点。我们也在CIFAR-10数据集上检验了这个方案的效果：一个四层的CNN没有正则化时实现了13%的错误率，有正则化时实现了11%的错误率。</p>
<h5 id="34-overlapping-pooling">3.4 Overlapping Pooling<a class="headerlink" href="#34-overlapping-pooling" title="Permanent link">&para;</a></h5>
<p>CNN中的池化层总结了同一核映射中相邻组神经元的输出。传统上，相邻池化单元总结的邻居没有重叠。更准确地说，池化层可以被认为是由间隔<span class="arithmatex"><span class="MathJax_Preview">s</span><script type="math/tex">s</script></span>像素的池化单元组成的网格，每个池化单元组成一个大小为<span class="arithmatex"><span class="MathJax_Preview">z\times z</span><script type="math/tex">z\times z</script></span>的邻域，该邻域位于池化单元的中间位置。如果我们设置<span class="arithmatex"><span class="MathJax_Preview">s=z</span><script type="math/tex">s=z</script></span>，我们得到的是像通常应用在CNN中的传统局部池化。如果我们设置<span class="arithmatex"><span class="MathJax_Preview">s&lt;z</span><script type="math/tex">s<z</script></span>，我们得到重叠池化。这就是我们在网络中所使用的，<span class="arithmatex"><span class="MathJax_Preview">s=2</span><script type="math/tex">s=2</script></span>和<span class="arithmatex"><span class="MathJax_Preview">z=3</span><script type="math/tex">z=3</script></span>。这个方案与非重叠方案<span class="arithmatex"><span class="MathJax_Preview">s=2,z=2</span><script type="math/tex">s=2,z=2</script></span>相比，分别降低了top-1、top-5错误率0.4%、0.3%，它产生了相同维度的输出。在训练过程中，我们通常观察到有重叠池化的模型更难过拟合。</p>
<h5 id="35-overall-architecture">3.5 Overall Architecture<a class="headerlink" href="#35-overall-architecture" title="Permanent link">&para;</a></h5>
<p>现在我们准备去描述CNN的完整结构。正如图二所示，网络包含8个带权重的层；前五层是卷积层，剩下三层是全连接层。最后的全连接层的输出被传送到1000路softmax层，这产生了1000类标签的分布。我们的网络使多项式逻辑回归最大化，这相当于预测分布下最大化正确标签的对数概率的平均值。</p>
<p>第2、4、5卷积层仅仅连接到同一块CPU上的前面层的核上。第3卷积层连接到第2卷积层的所有核。全连接层的神经元连接到前面层的所有神经元。正则化响应层紧随第1、2卷积层。最大池化层紧随正则化响应层，如第5卷积层。ReLU非线性激活函数被应用到每个卷积层和全连接层的输出。</p>
<p>第1卷积层用<span class="arithmatex"><span class="MathJax_Preview">11\times11\times3</span><script type="math/tex">11\times11\times3</script></span>的96个核以4像素为步长过滤<span class="arithmatex"><span class="MathJax_Preview">224\times224\times3</span><script type="math/tex">224\times224\times3</script></span>的输入图像（步长是核映射的邻域神经元的接受野中心的距离）。第2卷积层以第1卷积层的输出作为输入，用<span class="arithmatex"><span class="MathJax_Preview">5\times5\times48</span><script type="math/tex">5\times5\times48</script></span>大小的256个核过滤输入。第3、4、5卷积层彼此连接并且没有池化或者正则化层。第3卷积层有<span class="arithmatex"><span class="MathJax_Preview">3\times3\times256</span><script type="math/tex">3\times3\times256</script></span>大小的384个核连接到第2卷积层正则化池化后的输出。第4卷积层有<span class="arithmatex"><span class="MathJax_Preview">3\times3\times192</span><script type="math/tex">3\times3\times192</script></span>大小的384个核，并且第5卷积层有<span class="arithmatex"><span class="MathJax_Preview">3\times3\times192</span><script type="math/tex">3\times3\times192</script></span>大小的256个核。全连接层有4096个神经元。</p>
<blockquote>
<p>框表示每一层数据的大小。随着网络加深，慢慢压缩空间信息，语义空间增加，通道数增加，每个通道看特定的模式。 人能看懂的变成机器能识别的。 
</p>
</blockquote>
<h4 id="4-reducing-overfittting">4. Reducing Overfittting<a class="headerlink" href="#4-reducing-overfittting" title="Permanent link">&para;</a></h4>
<p>我们的神经网络有6千万个参数。尽管1000类让训练样本从图像到标签的映射施加了10位的约束，没有相当大的过拟合学习如此多的参数证明是不充分的。下面，我们描述我们对抗过拟合的两种主要方式。</p>
<h5 id="41-data-augmentation">4.1 Data Augmentation<a class="headerlink" href="#41-data-augmentation" title="Permanent link">&para;</a></h5>
<p>在图像数据上减少过拟合的最简单和最常见的方式是用标签保留转换人工扩大数据集。我们运用了数据增强的两种不同形式，两种形式都允许转换的图像用很少的计算从原始图像产生，因此转换的图像不必存储在硬盘上。在我们的实现中，转换的图像从CPU上的Python代码产生，然而GPU在之前的批量图像上训练。因此，这些数据增强方案实际上无需计算。</p>
<p>第一种数据增强形式包括产生图像转换和水平反射。我们通过从256 x 256的图像中随机提取224 x 224个patch(以及它们的水平反射)，并在这些提取的patch上训练我们的网络。这将我们的训练规模增加了2048倍，尽管最终的训练样本是高度相互依赖的。如果没有这个方案，我们的网络会遭受严重的过拟合，这将迫使我们使用更小的网络。在测试时，网络通过提取5个224 x 224的patch(四个边角patch和中心patch)及其水平反射(总共10个patch)进行预测，并将网络的softmax层对这10个patch的预测取平均。</p>
<p>数据增强的第二种形式是改变训练图像中RGB通道的强度。具体来说，我们在ImageNet训练集上的RGB像素值集执行PCA算法。对每个训练图像，我们增加了主成分的倍数，其大小正比于相应的特征值乘以一个从均值为0、标准差为0.1的高斯函数中提取的随机变量。因此，对每个RGB图像像素<span class="arithmatex"><span class="MathJax_Preview">I_{xy}=[I_{xy}^R,I_{xy}^G,I_{xy}^B]^T</span><script type="math/tex">I_{xy}=[I_{xy}^R,I_{xy}^G,I_{xy}^B]^T</script></span>，我们增加了下面的量：
$$
[P_1,P_2,P_3][\alpha_1\lambda_1,\alpha_2\lambda_2,\alpha_3\lambda_3]^T
$$
在这<span class="arithmatex"><span class="MathJax_Preview">P_i</span><script type="math/tex">P_i</script></span>和<span class="arithmatex"><span class="MathJax_Preview">\lambda_i</span><script type="math/tex">\lambda_i</script></span>分别是<span class="arithmatex"><span class="MathJax_Preview">3\times3</span><script type="math/tex">3\times3</script></span>的RGB像素值的协方差矩阵的第i个特征向量和特征值，<span class="arithmatex"><span class="MathJax_Preview">\alpha_i</span><script type="math/tex">\alpha_i</script></span>是前面提到的随机变量。每个<span class="arithmatex"><span class="MathJax_Preview">\alpha_i</span><script type="math/tex">\alpha_i</script></span>仅仅从特定训练图像的所有像素中提取，直到图像再次被用来训练，在这个点上，它被重新提取。这个方案大概捕捉了自然图像的重要性质，也就是说，目标特性对于光亮的颜色和强度的变化是不变的。 这个方案将top-1错误率降低了超过了1%。</p>
<h5 id="42-dropout">4.2 Dropout<a class="headerlink" href="#42-dropout" title="Permanent link">&para;</a></h5>
<p>许多不同模型的预测的结合是降低测试误差的非常成功的方式，但是这似乎对于已经训练了很多天的大规模神经网络是代价高昂的。然而，这有一个非常高效的模型融合版本，它在训练时仅仅花两倍的时间。最近引入的技术，称为“dropout”，将每个隐藏神经元的输出以0.5的概率设置为0。以这种方式丢掉的神经元对前向传递没有贡献，也不参与后向传播。所以每次一个输入进来，神经网络都是一个不同的结构，但是所有的这些结构共享权重。这种技术减少了神经元复杂的协同适应，因此一个神经元不能依赖于特定其他神经元的存在。因此不得不学习更多在连接许多其他神经元的不同的随机子集方面有用的健壮的特征。测试时，我们用所有的神经元但是将他们的输出乘以0.5，取dropout网络产生的预测分布的几何平均值是合理的近似。</p>
<p>我们在图2的前两个全连接层中使用dropout技术。没有dropout，我们的网络表现出严重的过拟合。Dropout大概使收敛所需的迭代次数翻倍。</p>
<blockquote>
<p>Dropout等价于很多模型做融合，现在认为dropout在现行模型下等价于一个L2正则项，相当于正则的效果，无法构造出一个跟他相等的正则的东西。中间2个很大的全连接是设计缺陷。</p>
</blockquote>
<h4 id="5-details-of-learning">5. Details of learning<a class="headerlink" href="#5-details-of-learning" title="Permanent link">&para;</a></h4>
<blockquote>
<p>SGD（随机梯度优化）是训练深度学习最常用的优化算法。L-BFGS、Gradient Descent。sgd里面的噪音对模型泛化性是有好处的。weight decay在当时机器学习界叫做L2 regularization，加在优化算法上。momentu随机化初始化的方差0.01</p>
</blockquote>
<p>我们用随机梯度下降训练我们的模型，128个样本的批处理大小，0.9的冲量，0.0005的权值衰减。我们发现这个很小数量的权值衰减对模型去学习很重要。换句话说，权值衰减这儿不仅仅是正则化项：它减小了模型的训练误差。权重<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>的更新规则是：
$$
v_{i+1}:=0.9\cdot v_i-0.0005\cdot \epsilon \cdot w_i-\epsilon \cdot \left \langle \frac{\partial L}{\partial w}|<em>{w_i} \right \rangle</em>{D_i}\
w_{i+1}:=w_i+v_{i+1}
$$
这儿<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>是迭代次数，<span class="arithmatex"><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>是冲击变量，<span class="arithmatex"><span class="MathJax_Preview">\epsilon</span><script type="math/tex">\epsilon</script></span>是学习率，<span class="arithmatex"><span class="MathJax_Preview">\left \langle \frac{\partial L}{\partial w}\mid_{w_i} \right \rangle_{D_i}</span><script type="math/tex">\left \langle \frac{\partial L}{\partial w}\mid_{w_i} \right \rangle_{D_i}</script></span>是第<span class="arithmatex"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>批<span class="arithmatex"><span class="MathJax_Preview">D_i</span><script type="math/tex">D_i</script></span>关于<span class="arithmatex"><span class="MathJax_Preview">w</span><script type="math/tex">w</script></span>求导的平均值，在<span class="arithmatex"><span class="MathJax_Preview">w_i</span><script type="math/tex">w_i</script></span>处求导。</p>
<p>我们以平均值为0、标准差为0.01的高斯分布初始化每层的权重。我们在第2、4、5卷积层和全连接隐藏层使用常量1初始化偏差。初始化通过给ReLU一个正向的输入加快了早期阶段的学习。我们用常量0在剩下的层初始化偏差。</p>
<p>我们对所有的层使用相同的学习率，我们在训练时手动调整学习率。我们遵循的启发式方法是，当验证错误率随着当前学习率停止改善时，将学习率除以10。学习率初始化为0.01，结束时减少了三倍。我们在120万张图像的训练集上对网络进行了大约90个周期的训练，这在两个NVIDIA GTX 580 3GB gpu上花费了5到6天的时间。</p>
<h4 id="6-results">6. Results<a class="headerlink" href="#6-results" title="Permanent link">&para;</a></h4>
<p>我们的ILSVRC-2010的结果总结在表1中。我们的网络实现的top-1和top-5的测试错误率是37.5%和17.0%。一种取6个在不同特征上训练的稀疏编码模型得出预测值的平均值方法在ILSVRC-2010竞赛中实现的最好表现是47.1%和28.2%，自那之后的报道的最好结果是45.7%和25.7%，这是一种在两种密集采样的特征计算得到的FV上训练的两个分类器给出的预测值的平均的方法。</p>
<p>我们也在ILSVRC-2012竞赛中输入我们的模型，并在表2中报告了我们的结果。自从ILSVRC-2012竞赛，测试集标签不能公开得到，我们不能报告我们尝试过的所有模型的测试误差。在这段剩下部分，我们交叉使用验证错误率和测试错误率，因为在我们的实验中，这两种错误率差别不超过0.1%。这篇文章描述的CNN实现了18.2%的top-5错误率。对5个相似的CNN的预测值取平均得到了16.4%的错误率。训练一个CNN，在最后一个池化层上增加了一个额外的第6卷积层，来对整个ImageNet Fall 2011公开数据集进行分类(1500万张图像，22000类)，然后在ILSVRC-2012上“微调”它给出的错误率为16.6%。将在ImageNet Fall 2011公开数据集预先练的两个CNND预测值和上述提到过的5个CNN的预测值平均，得到的错误率为15.3%。第二名的最好成绩是26.2%。</p>
<p>最后我们也报告了在有10184类和890万张图像的ImageNet Fall 2009数据集上的错误率。在这个数据集上，我们遵循文献中使用一半的图像用于训练，一半用于测试的约定。由于没有现成的测试集，我们的分割必然不同于以前的作者使用的分割，但这不会明显地影响结果。我们在这个数据集上的top-1、top-5的错误率是67.4%和40.9%，这个结果是上述的但在最后的池化层后有一个额外的第6卷积层的网络中得到的。在这个数据集上的最好报道结果是78.1%和60.9%。</p>
<h5 id="61-qualitative-evaluations">6.1 Qualitative Evaluations<a class="headerlink" href="#61-qualitative-evaluations" title="Permanent link">&para;</a></h5>
<p>图3显示了由网络的两个数据连接层学习到的卷积核。这个网络已经学会了各种频率和方向选择的核，以及学习不同颜色的斑点的核。注意两个GPU表现出的专门化，这是第3.5节中描述的连接受限的结果。GPU1的核很大程度上是颜色无关的，而GPU2的核很大程度上是颜色特定的。这种专门化发生在每次运行期间，并且独立于任何特定的随机权重初始化(对GPU的重新编号取模)。</p>
<p>在图4的左半边，我们通过计算网络在八张测试图像上的top-5预测情况定性评估网络学到了什么。注意到网络能识别出甚至是偏离中心的物体，例如左上方的小虫。top-5标签中的绝大多数似乎是合理的。例如，只有其他种类的猫被认为是豹子的合理标签。在一些情形下，图像的目的焦点真的有点不明确。</p>
<p>另一种探究网络的视觉知识的方法是考虑最后的4096维隐藏层图像诱导的特征激活。如果两张图像产生了一个小的欧氏距离间隔的特征激活向量，我们可以说更高层的神经网络认为它们是相似的。图4显示了测试集中的五张图像和训练集中根据这种度量最相似的六张图片。注意在像素级上，检索到的训练图像在L2度量上通常与第一列中的查询图像不接近。例如，被找回的狗和大象会摆出各种姿势。我们在补充材料中给出了更多测试图像的结果。</p>
<p>用两个4096维实值向量之间的欧氏距离来计算相似度是低效的，但通过训练自编码器将这些向量压缩成简短的二进制码可以提高效率。这将产生一种比对原始像素应用自动编码器好得多的图像检索方法，后者不使用图像标签，因此倾向于检索具有相似边缘模式的图像，无论它们在语义上是否相似。</p>
<h4 id="7-discussion">7. Discussion<a class="headerlink" href="#7-discussion" title="Permanent link">&para;</a></h4>
<p>我们的结果表明，仅仅使用监督学习，一个很大的、很深的卷积神经网络就能够在一个具有高度挑战性的数据集上实现破纪录的结果。如果去掉一层神经网络，我们网络的性能会下降。例如，移除任何中间层会给网络性能带来2%个点的损失。所以深度、网络有多深对于实现我们的结果是非常重要的。</p>
<p>为了简化我们的实验，我们没有做任何无监督预训练（深度学习很长时间关注有标号的数据），即使我们预计这会有帮助，尤其当我们获得足够的计算能力可以显著增加网络的尺寸，但没有在有标签数据的数量上获得相应的增长。到目前为止，我们的结果已经得到了改善，因为我们把我们的网络做得更大，训练得更久，但为了匹配人类视觉系统的下时间路径，我们仍有很大数量级的工作要做。最终，我们将在视频序列上使用非常大且深的卷积网络，视频序列的时序结构提供了非常有用的信息，而这些信息在静态图像中是缺失的或者很不明显。</p>
<h2 id="resnet">Resnet<a class="headerlink" href="#resnet" title="Permanent link">&para;</a></h2>
<p>Randy-CMU的教授</p>
                
                  
                
              
              
                 
 
   
<!-- <hr><blockquote class="page-copyright">
  <span><i class="md-icon">build</i>本页面最近更新：</span><span class="facts_modified"></span>，<a class="edit_history">更新历史</a><br>
  <span><i class="md-icon">edit</i>发现错误？想一起完善？ <a href="https://github.com/WWeiying/edit/master/docs/start/ai.md" title="编辑此页" class="page_edit_url">在 GitHub 上编辑此页！</a></span><br>
  <span><i class="md-icon">people</i>本页面贡献者：</span><span class="page_contributors">Wang Weiying</span><br>
  <span><i class="md-icon">copyright</i>本页面的全部内容在 <strong><a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh">CC BY-SA 4.0</a> 和 <a href="https://github.com/zTrix/sata-license">SATA</a></strong> 协议之条款下提供，附加条款亦可能应用</span>
</blockquote> -->


<h2 id="__comments" data-no-instant>评论</h2>
<form id="gitalk-form" onsubmit="return!1" data-no-instant>
<div id="gitalk-container" data-no-instant>
</div>
</form>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script>
  var gitalk = new Gitalk({
    id: '人工智能',
    owner: 'WWeiying',
    repo: 'WWeiying.github.io',
    admin: ['WWeiying'],
    clientID: 'd3dc000b2047f49b2bd8',
    clientSecret: 'b20c67ecf9762b0de64976355994ac758d506962',
    distractionFreeMode: false,
    pagerDirection: 'first'
  })
  gitalk.render('gitalk-container')
</script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<script>function scrollFunction(){20<document.body.scrollTop||20<document.documentElement.scrollTop?document.getElementById("myBtn").style.display="block":document.getElementById("myBtn").style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}window.onscroll=function(){scrollFunction()}</script>
<button onclick="topFunction()" id="myBtn" class="data-tip-left" data-tip="回到顶部">
  <svg class="Zi Zi--BackToTop data-tip-left" data-tip="回到顶部" fill="currentColor" viewBox="0 0 24 24" width="24" height="24">
    <path d="M16.036 19.59a1 1 0 0 1-.997.995H9.032a.996.996 0 0 1-.997-.996v-7.005H5.03c-1.1 0-1.36-.633-.578-1.416L11.33 4.29a1.003 1.003 0 0 1 1.412 0l6.878 6.88c.782.78.523 1.415-.58 1.415h-3.004v7.005z"></path>
  </svg>
</button>
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../format/" title="格式" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                格式
              </span>
            </div>
          </a>
        
        
          <a href="../../website/" title="网站和工具" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                网站和工具
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2022 WWeiying
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
        <div id="miitbeian"></div>
      </div>
      
      <span style="float:right" class="build_date_utc"><a href="https://github.com/24OI/OI-wiki">最近更新：, 2022-05-04</a></span>
      <script>
        /* miitbeian */
        if (window.location.hostname == "oi-wiki.com") {
          document.getElementById("miitbeian").innerHTML = `<a href="http://beian.miit.gov.cn/">黑ICP备19005132号-2</a>`;
        }
        /* Easter Egg */
        console.log(`%c OI Wiki %c  %c`,"background:#35495e ; padding: 1px; border-radius: 3px 0 0 3px;  color: #fff","background:#41b883 ; padding: 1px; border-radius: 0 3px 3px 0;  color: #fff","background:transparent");
        console.log('少年，恭喜你囍提彩蛋，我们在做一些 OI 相关的有趣的事情，如果您对此感兴趣，欢迎访问 https://join-us.oi-wiki.org');
      </script>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.411a9f9f.js"></script>
      <script>app.initialize({version:"1.2.4",url:{base:"../.."}}),"serviceWorker"in navigator&&navigator.serviceWorker.register("/service-worker.js",{scope:"/"}).then(function(e){console.log("PWA Registration succeeded. Scope is "+e.scope)}).catch(function(e){console.log("PWA Registration failed with "+e)})</script>
      
        <script src="../../_static/js/extra.js?v=16"></script>
      
        <script src="../../assets/vendor/mathjax/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="../../_static/js/baidu_tongji.js"></script>
      
    
  </body>
</html>